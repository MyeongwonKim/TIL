## 개념
- 스파크의 목표: '빅데이터 애플리케이션 개발에 필요한 통합 플랫폼 제공'
- 아파치 스파크는 빅데이터를 위한 통합 컴퓨팅 엔진이며 클러스터 환경에서 데이터를 병렬로 처리하는 라이브러리의 집합임
- 네 가지 언어(python, java, scala, R)를 지원 / scala로 구현되어 있으며 JVM 기반으로 동작함
- 다양한 저장소를 지원하고, 데이터 저장 위치에 상관없이 처리에 집중하도록 만들어짐
- 통합형 라이브러리 제공: spark SQL, 머신러닝을 지원하는 MLlib, 스티림 처리 기능인 spark streaming, 그래프 분석 엔진 GraphX 등
- 로컬 환경/ 하둡 클러스터/ 클라우드 상에서 설치 및 실행 가능

## 등장 배경 및 역사
- 프로세서의 속도가 매년 빨라지던 시기에는 대규모 데이터의 처리를 프로세서의 성능 향상에 맡겼음
- 2005년 경 물리적 방열 한계로 단일 프로세서의 성능 향상이 멈추고, 병렬 CPU 코어를 추가하여 성능 향상을 꾀함
- 이런 상황에서도 데이터 저장 및 수집 기술은 계속 향상되어 엄청난 양의 데이터가 양산됨 -> 데이터 병렬 처리 엔진이 필요해짐
- 클러스터에서 데이터를 병렬로 처리하는 최초의 오픈소스 시스템인 하둡 맵리듀스의 단점을 보완하여 스파크가 개발됨
- 함수형 프로그래밍 기반 API / 연산 단계 사이에서 메모리에 저장된 데이터를 공유 -> 효율성 향상

[스파크 완벽 가이드] - chapter 1 에서 요약 정리함

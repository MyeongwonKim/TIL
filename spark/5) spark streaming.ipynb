{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스트림 처리의 기초\n",
    "- DStream: 자바나 파이썬 객체에 대한 저수준 연산만 지원하기 때문에 고수준 최적화 기법을 활용하는데 한계가 있음. 이벤트 시간 처리를 지원하지 않음\n",
    "- 구조적 Streaming: 2016년 DataFrame 기반으로 구현된 신규 스트리밍 API. DataFrame이나 Dataset과 통합 가능. 이벤트 시간 데이터 처리를 지원\n",
    "- 스트리밍의 장점: 사용자 응답을 위한 대기 시간이 짧으며, 연산 결과의 증분이 생성되므로 효율적임\n",
    "- 스트리밍의 과제: 높은 데이터 처리량, 빠른 처리, 순서가 뒤섞인 데이터 처리, 입력값과 출력값에 대한 트랜잭션 보장 등\n",
    "\n",
    "### Stream processing\n",
    "- 신규 데이터를 끊임없이 처리해 결과를 만드는 행위. 입력 데이터 (이벤트 스트림)이 도착한 후 다양한 쿼리 연산을 수행하여 결과를 출력하거나 외부 sink 시스템에 데이터를 저장함\n",
    "- 배치 처리: 고정된 입력 데이터셋을 다루는 데이터 처리. 결과가 한번 산출됨. 스트리밍과 배치 연산은 조인하여 사용되는 경우가 있음\n",
    "\n",
    "### Stream 처리 사례\n",
    "1. Notification and Alerting: 특정 이벤트나 이벤트 패턴 탐지시 이를 알림\n",
    "2. 실시간 리포트: 실시간 대시보드 구현\n",
    "3. 실시간 데이터 제공: 예시는 웹 UI에서 최신 방문자 수 조회 (구글 애널리틱스)\n",
    "4. 실시간 의사결정: 신규 입력을 분석하고 비즈니스 로직에 따라 처리함. 예시는 부정행위에 속하는 카드 트랜잭션 거부\n",
    "5. 온라인 머신러닝: 실시간 데이터와 이력 데이터를 조합해서 모델 학습\n",
    "\n",
    "## 구조적 스트리밍의 기초 \n",
    "- 스파크 SQL 엔진 기반의 스트림 처리 프레임워크\n",
    "- 스트림 데이터를 데이터가 계속 추가되는 테이블처럼 다룸. 쿼리 구문을 변경하지 않고 계속 사용\n",
    "- 출력 모드: append (싱크에 신규 레코드 추가), update (대상 레코드 갱신), complete (전체 출력 내용 재작성)\n",
    "- 트리거: 데이터 출력 시점을 정의\n",
    "- 몇가지 제약을 제외하고 기본적으로 정적인 구조적 API의 모든 트랜스포메이션을 스트리밍 DataFrame에서도 사용 가능\n",
    "\n",
    "### 구조적 스트리밍 활용\n",
    "- 데이터셋: 인간 행동 인지를 위한 이기종 (heterogeneity) 데이터셋. 사용자의 자전거 타기, 앉기, 일어서기, 걷기 등의 활동을 기록한 센서 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.123.105:4041\n",
       "SparkContext available as 'sc' (version = 2.3.2, master = local[*], app id = local-1597802677585)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "static: org.apache.spark.sql.DataFrame = [Arrival_Time: bigint, Creation_Time: bigint ... 8 more fields]\r\n",
       "dataSchema: org.apache.spark.sql.types.StructType = StructType(StructField(Arrival_Time,LongType,true), StructField(Creation_Time,LongType,true), StructField(Device,StringType,true), StructField(Index,LongType,true), StructField(Model,StringType,true), StructField(User,StringType,true), StructField(gt,StringType,true), StructField(x,DoubleType,true), StructField(y,DoubleType,true), StructField(z,DoubleType,true))\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val static = spark.read.json(\"c:/SparkDG/data/activity-data/\")\n",
    "val dataSchema = static.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "streaming: org.apache.spark.sql.DataFrame = [Arrival_Time: bigint, Creation_Time: bigint ... 8 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 정적 DataFrame의 dtatSchema 객체를 사용해 스티리밍의 schema 지정\n",
    "val streaming = spark.readStream.schema(dataSchema)\n",
    "    .option(\"maxFilesPerTrigger\", 1).json(\"c:/SparkDG/data/activity-data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activityCounts: org.apache.spark.sql.DataFrame = [gt: string, count: bigint]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// groupBy Transformation 수행 (지연 연산) : 각 행동 별로 그룹을 짓고 count\n",
    "val activityCounts = streaming.groupBy(\"gt\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "// shuffle partition 수 줄이기\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activityQuery: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@5a55442f\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 스트림 쿼리의 액션 정의. memory sink에 complete 출력 모드로 출력\n",
    "val activityQuery = activityCounts.writeStream.queryName(\"activity_counts\")\n",
    "    .format(\"memory\").outputMode(\"complete\")\n",
    "    .start()\n",
    "// activityQuery.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|       sit|49238|\n",
      "|     stand|45539|\n",
      "|stairsdown|37459|\n",
      "|      walk|53024|\n",
      "|  stairsup|41809|\n",
      "|      null|41791|\n",
      "|      bike|43187|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|       sit|73855|\n",
      "|     stand|68309|\n",
      "|stairsdown|56192|\n",
      "|      walk|79536|\n",
      "|  stairsup|62710|\n",
      "|      null|62688|\n",
      "|      bike|64781|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|       sit|86163|\n",
      "|     stand|79694|\n",
      "|stairsdown|65557|\n",
      "|      walk|92792|\n",
      "|  stairsup|73162|\n",
      "|      null|73136|\n",
      "|      bike|75579|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|110778|\n",
      "|     stand|102464|\n",
      "|stairsdown| 84286|\n",
      "|      walk|119304|\n",
      "|  stairsup| 94067|\n",
      "|      null| 94033|\n",
      "|      bike| 97175|\n",
      "+----------+------+\n",
      "\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|123085|\n",
      "|     stand|113849|\n",
      "|stairsdown| 93648|\n",
      "|      walk|132560|\n",
      "|  stairsup|104521|\n",
      "|      null|104482|\n",
      "|      bike|107974|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (i <- 1 to 5) {\n",
    "    spark.sql(\"select * from activity_counts\").show()\n",
    "    Thread.sleep(1000)             // 1초 마다 출력\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|246159|\n",
      "|     stand|227709|\n",
      "|stairsdown|187264|\n",
      "|      walk|265119|\n",
      "|  stairsup|209082|\n",
      "|      null|208954|\n",
      "|      bike|215949|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from activity_counts\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|258467|\n",
      "|     stand|239093|\n",
      "|stairsdown|196623|\n",
      "|      walk|278375|\n",
      "|  stairsup|219543|\n",
      "|      null|219400|\n",
      "|      bike|226746|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from activity_counts\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|258467|\n",
      "|     stand|239093|\n",
      "|stairsdown|196623|\n",
      "|      walk|278375|\n",
      "|  stairsup|219543|\n",
      "|      null|219400|\n",
      "|      bike|226746|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from activity_counts\").show()\n",
    "// 파일 완전히 다 읽음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deviceModelStats: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@d48a0c5\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 행동, 모델로 그룹지은 후 가소도 센서를 의미하는 x,y,z 값의 평균 집계\n",
    "val deviceModelStats = streaming.cube(\"gt\", \"model\").avg()\n",
    "   .drop(\"avg(Arrival_time)\")\n",
    "   .drop(\"avg(Creation_time)\")\n",
    "   .drop(\"avg(Index)\")\n",
    "   .writeStream.queryName(\"device_counts\").format(\"memory\").outputMode(\"complete\")\n",
    "   .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|       sit|  null|-5.18435580910910...|2.377098624126100...|-2.00212909006953...|\n",
      "|     stand|  null|-3.21765845070747...|3.048037742372213...|2.057814180385872E-4|\n",
      "|       sit|nexus4|-5.18435580910910...|2.377098624126100...|-2.00212909006953...|\n",
      "|     stand|nexus4|-3.21765845070747...|3.048037742372213...|2.057814180385872E-4|\n",
      "|      null|  null|-0.00759977381558...|4.153276995856867...|0.003198222304879...|\n",
      "|      null|  null| 7.16400359378949E-4|-0.00687358266758...|-0.00935555711419...|\n",
      "|      walk|  null|-0.00441871154414...|0.002042781062758...|6.729268533703832E-5|\n",
      "|      null|nexus4|-0.00759977381558...|4.153276995856867...|0.003198222304879...|\n",
      "|      null|nexus4| 7.16400359378949E-4|-0.00687358266758...|-0.00935555711419...|\n",
      "|      bike|  null|0.022988712178907245|-0.01041922896671...|-0.08254010658960201|\n",
      "|  stairsup|  null| -0.0254423932856748|-0.00990018005783832|-0.09901152685191157|\n",
      "|stairsdown|  null|0.023675364574222757|-0.03823912330772138| 0.12413775718587758|\n",
      "|      bike|nexus4|0.022988712178907245|-0.01041922896671...|-0.08254010658960201|\n",
      "|      walk|nexus4|-0.00441871154414...|0.002042781062758...|6.729268533703832E-5|\n",
      "|stairsdown|nexus4|0.023675364574222757|-0.03823912330772138| 0.12413775718587758|\n",
      "|  stairsup|nexus4| -0.0254423932856748|-0.00990018005783832|-0.09901152685191157|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from device_counts\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

## 하둡과 맵리듀스
### 배경 및 역사
- 빅데이터가 곳곳에서 생산되는 시대
- 디스크의 용량은 커졌으나 (1TB 정도) 전송 속도는 100MB/s 수준임 -> 디스크 전체를 읽는데 2.5시간이 걸림
- 해결책: 여러 개의 디스크에서 동시에 데이터를 읽는 것
  - 문제1: 많은 하드웨어를 사용하는 만큼 장애 가능성도 증가함. 이를 대비하여 데이터를 여러 디스크에 복제해야함
  - 문제2: 분석을 위해서는 분할된 데이터들을 하나로 결합해야함. 맵리듀스가 이를 해결
- 2003년 발표된 구글의 GFS, 2004년 발표된 구글의 맵리듀스에 착안한 너치 분산 파일시스템으로 시작
- 2006년 하둡이라는 이름의 프로젝트로 분리되어 나와서 야후팀과 합류한 후, 야후에서 2008년 하둡 클러스터 구현 및 발표

### 특징
- 데이터를 클러스터에 분할하여 저장하고, 맵과 리듀스 함수를 사용해 분리된 파티션들에서 병렬로 데이터를 처리함
- 전체 데이터셋을 대상으로 일괄 분석이 가능함. 대화형 분석에는 적합하지 않음
- 한번 쓰고 여러번 읽는 애플리케이션에 적합함
- 텍스트나 이미지와 같은 비정형 데이터도 잘 처리함. schema-on-read
- 정규화를 수행하지 않음. 매번 모든 데이터를 완전하게 표시함
- 분산 컴퓨팅 시 실패한 프로세스를 자동으로 감지하여 장애가 없는 머신에 재배치하도록 구현됨
- RDBMS: 지속적으로 변경되는 데이터셋에 적합함. 정형화된 데이터를 다룸. 중복 제거와 무결성을 위해 정규화가 필요

### 분산 컴퓨팅에 대비한 멀티 프로세싱의 문제점
1) 일 분산의 문제: 파일별 크기가 다를 경우 결국 가장 긴 파일을 처리하는 프로세스의 처리 시간에 의해 전체 수행 시간이 결정됨. 이를 위한 대안은 전체 파일을 일정 단위의 데이터 청크로 나누고 각 청크를 하나의 프로세스에 할당하는 것
2) 결과 통합의 문제: 개별 프로세스의 모든 결과를 합친 다음 이에 대한 처리를 다시 수행해야함
3) 단일 머신의 처리 능력 한계

### 맵리듀스 기본
- 맵 단계와 리듀스 단계는 둘 다 입력과 출력으로 키-값의 쌍을 사용한다. (데이터 타입은 선택)
- 예시: 기상 센서의 로그 데이터로부터 연도별 최고 기온 구하기
  - 맵 함수의 입력: (file offset, 문자열 형태의 로그 데이터)
  - 맵 함수의 출력: (연도, 기온) -> 키를 기준으로 정렬 및 그룹화
  - 리듀스 함수의 입력: (연도, [기온1, 기온2, ...])
  - 리듀스 함수의 출력: (연도, 최고 기온)
  - 구성: Mapper class, Reducer class, Mapreduce Job class
- 일반적으로 전체 데이터를 128MB의 스플릿으로 분리하여 병렬 처리함
- 맵 태스크의 결과는 로컬 디스크에 저장되고, 맵리듀스 잡이 완료된 후 맵의 결과는 버려진다. 리듀스의 결과는 안정성을 위해 HDFS에 저장됨
- 리듀스 태스크의 수는 독립적으로 지정 가능. 이 수는 잡의 실행 시간에 영향을 크게 미치므로 튜닝이 필요함 
- 다수의 리듀스 태스크가 존재하는 경우: 리듀스 태스크의 수 많큼 파티션이 생성되며 각 파티션에 맵의 결과가 분배됨 ('셔플')
- 컴바이너 함수: 맵 함수의 결과를 그룹화하여 리듀스 함수의 입력으로 보냄

## HDFS
### 특징
- 높은 데이터 처리량(TB~PB)을 위해 최적화되어 있고 응답 시간은 희생됨
- 따라서 빠른 응답 시간을 요구하는 application은 HDFS와 맞지 않음
- 
